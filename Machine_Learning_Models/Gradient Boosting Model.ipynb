{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e56c3f9",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Which of the following is/are TRUE about gradient boosting trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88baf3",
   "metadata": {},
   "source": [
    "(a) In gradient boosting trees, the decision trees are independent of each other.\\\n",
    "(b) In gradient boosting trees, the decision trees are dependent of each other.\\\n",
    "(c) It is a method for improving the performance by aggregating the results of several decision\n",
    "trees.\\\n",
    "(d) (a) and (b)\\\n",
    "(e) (a) and (c)\\\n",
    "(f) (b) and (c)\n",
    "\n",
    "#### (f) (b) and (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61581a86",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### Suppose you are given the following scenario for training and validation for gradient boosting trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cedd068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Training Error</th>\n",
       "      <th>Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario  Depth  Training Error  Validation Error\n",
       "0         1      2             100               110\n",
       "1         2      4              90               105\n",
       "2         3      6              50               100\n",
       "3         4      8              45               105\n",
       "4         5     10              30               150"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Scenario = pd.DataFrame({\"Scenario\": [1, 2, 3, 4, 5], \n",
    "                       \"Depth\": [2, 4, 6, 8, 10], \n",
    "                       \"Training Error\": [100, 90, 50, 45, 30], \n",
    "                       'Validation Error': [110, 105, 100, 105, 150]})\n",
    "Scenario.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f3cc7",
   "metadata": {},
   "source": [
    "I would choose scenario 2 because it has one of the smallest validation error and its training error is similar to the validation error. Notice that there are other scenarios such as scenario 3 has the smallest validation error; however, the training error is much smaller than the\n",
    "validation error, which indicates that the model might be over-fitting the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b80d9a",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### In this course have covered two boosting frameworks. What is the main difference between AdaBoost and Gradient Boosting? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c4b60",
   "metadata": {},
   "source": [
    "AdaBoost focuses on correctly predict observations that were incorrectly predicted on initial iterations. On the other hand, gradient boosting focuses on minimizing the loss function of initial iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b517f",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Does the gradient boosting classifier model always outperforms the random forest model? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cc9f6b",
   "metadata": {},
   "source": [
    "No. Sometimes the gradient boosting classiâ€€er outperforms the random forest but not always."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca0e7d",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857a74f",
   "metadata": {},
   "source": [
    "#### (a) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54d81a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question 6\n",
    "#(a)\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "# Defining s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'gabrielferreira-data-455-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Defining the file to be read from s3 bucket\n",
    "key_file = 'framingham.csv'\n",
    "\n",
    "bucket_object = bucket.Object(key_file)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "# Reading csv\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "\n",
    "# Removing missing values\n",
    "heart = heart.dropna()\n",
    "heart.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577f5101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction:  0\n",
      "Interaction:  1\n",
      "Interaction:  2\n",
      "Interaction:  3\n",
      "Interaction:  4\n",
      "Interaction:  5\n",
      "Interaction:  6\n",
      "Interaction:  7\n",
      "Interaction:  8\n",
      "Interaction:  9\n",
      "Interaction:  10\n",
      "Interaction:  11\n",
      "Interaction:  12\n",
      "Interaction:  13\n",
      "Interaction:  14\n",
      "Interaction:  15\n",
      "Interaction:  16\n",
      "Interaction:  17\n",
      "Interaction:  18\n",
      "Interaction:  19\n",
      "Interaction:  20\n",
      "Interaction:  21\n",
      "Interaction:  22\n",
      "Interaction:  23\n",
      "Interaction:  24\n",
      "Interaction:  25\n",
      "Interaction:  26\n",
      "Interaction:  27\n",
      "Interaction:  28\n",
      "Interaction:  29\n",
      "Interaction:  30\n",
      "Interaction:  31\n",
      "Interaction:  32\n",
      "Interaction:  33\n",
      "Interaction:  34\n",
      "Interaction:  35\n",
      "Interaction:  36\n",
      "Interaction:  37\n",
      "Interaction:  38\n",
      "Interaction:  39\n",
      "Interaction:  40\n",
      "Interaction:  41\n",
      "Interaction:  42\n",
      "Interaction:  43\n",
      "Interaction:  44\n",
      "Interaction:  45\n",
      "Interaction:  46\n",
      "Interaction:  47\n",
      "Interaction:  48\n",
      "Interaction:  49\n",
      "Interaction:  50\n",
      "Interaction:  51\n",
      "Interaction:  52\n",
      "Interaction:  53\n",
      "Interaction:  54\n",
      "Interaction:  55\n",
      "Interaction:  56\n",
      "Interaction:  57\n",
      "Interaction:  58\n",
      "Interaction:  59\n",
      "Interaction:  60\n",
      "Interaction:  61\n",
      "Interaction:  62\n",
      "Interaction:  63\n",
      "Interaction:  64\n",
      "Interaction:  65\n",
      "Interaction:  66\n",
      "Interaction:  67\n",
      "Interaction:  68\n",
      "Interaction:  69\n",
      "Interaction:  70\n",
      "Interaction:  71\n",
      "Interaction:  72\n",
      "Interaction:  73\n",
      "Interaction:  74\n",
      "Interaction:  75\n",
      "Interaction:  76\n",
      "Interaction:  77\n",
      "Interaction:  78\n",
      "Interaction:  79\n",
      "Interaction:  80\n",
      "Interaction:  81\n",
      "Interaction:  82\n",
      "Interaction:  83\n",
      "Interaction:  84\n",
      "Interaction:  85\n",
      "Interaction:  86\n",
      "Interaction:  87\n",
      "Interaction:  88\n",
      "Interaction:  89\n",
      "Interaction:  90\n",
      "Interaction:  91\n",
      "Interaction:  92\n",
      "Interaction:  93\n",
      "Interaction:  94\n",
      "Interaction:  95\n",
      "Interaction:  96\n",
      "Interaction:  97\n",
      "Interaction:  98\n",
      "Interaction:  99\n"
     ]
    }
   ],
   "source": [
    "# Defining target and predictor variables\n",
    "X = heart[['age', 'totChol', 'sysBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "    \n",
    "# Creating lists to store the recall score for each model\n",
    "RFM_recall = list()\n",
    "ABM_recall = list()\n",
    "GBM_recall = list()\n",
    "\n",
    "# Creating lists to store the accuracy score for each model\n",
    "RFM_accuracy = list()\n",
    "ABM_accuracy = list()\n",
    "GBM_accuracy = list()\n",
    "\n",
    "# Creating for loop to get 100 recall and accuracy scores of each model\n",
    "for i in range(0,100):\n",
    "    \n",
    "    # (i) Splitting the dataset into train and test\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    #### (ii) Creating Random Forest Model\n",
    "    RF_md = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    RF_pred = RF_md.predict_proba(X_test)[:,1]\n",
    "    RF_pred = np.where(RF_pred > 0.1, 1, 0)\n",
    "    \n",
    "    # Computing Recall Score\n",
    "    RFM_recall.append(round(recall_score(Y_test, RF_pred), 2))\n",
    "    \n",
    "    # Computing Accuracy\n",
    "    RFM_accuracy.append(round(accuracy_score(Y_test, RF_pred), 2))\n",
    "    \n",
    "    #### (iii) Creating AdaBoost Model\n",
    "    AB_md = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators = 500).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    AB_pred = AB_md.predict_proba(X_test)[:,1]\n",
    "    AB_pred = np.where(AB_pred > 0.1, 1, 0)\n",
    "    \n",
    "    # Computing Recall Score\n",
    "    ABM_recall.append(round(recall_score(Y_test, AB_pred), 2))\n",
    "    \n",
    "    # Computing Accuracy Score\n",
    "    ABM_accuracy.append(round(accuracy_score(Y_test, AB_pred), 2))\n",
    "    \n",
    "    #### (iv) Creating Gradiet Boost Model\n",
    "    GB_md = GradientBoostingClassifier(max_depth = 3, n_estimators = 500).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    GB_pred = GB_md.predict_proba(X_test)[:,1]\n",
    "    GB_pred = np.where(GB_pred > 0.1, 1, 0)\n",
    "    \n",
    "    # Computing Recall Score\n",
    "    GBM_recall.append(round(recall_score(Y_test, GB_pred), 2))\n",
    "    \n",
    "    # Computing Accuracy Score\n",
    "    GBM_accuracy.append(round(accuracy_score(Y_test, GB_pred), 2))\n",
    "    print(\"Interaction: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07a27b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.8552</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metrics  RandomForest  AdaBoost  GradientBoosting\n",
       "0    Recall        0.8552      1.00            0.6335\n",
       "1  Accuracy        0.4525      0.15            0.5891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = pd.DataFrame({\"Metrics\": [\"Recall\", \"Accuracy\"],\n",
    "                               \"RandomForest\": [np.mean(RFM_recall), np.mean(RFM_accuracy)],\n",
    "                               \"AdaBoost\": [np.mean(ABM_recall), np.mean(ABM_accuracy)],\n",
    "                               \"GradientBoosting\": [np.mean(GBM_recall), np.mean(GBM_accuracy)]})\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d130e3",
   "metadata": {},
   "source": [
    "I would say the model that had the best performance was Gradieting Boost. Although it did not reach the minimum metrics, which are equal to 80%, it had the best balance between Recall and Accuracy among all models. I would recommend, in this case, to change or add hyper-parameters such as learning rate, increasing the cutoff value, or combining these above likelyhoods in a stroger prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c44d4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining target and predictor variables\n",
    "X = heart[['age', 'totChol', 'sysBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "# (i) Splitting the dataset into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb8be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradiet Boost Recall Score:  0.69\n",
      "Gradiet Accuracy Score:  0.66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### (iv) Creating Gradiet Boost Model\n",
    "GB_md = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "# Predicting on test dataset\n",
    "GB_pred = GB_md.predict_proba(X_test)[:,1]\n",
    "GB_label = np.where(GB_pred > 0.15, 1, 0)\n",
    "    \n",
    "# Computing Recall Score\n",
    "print(\"Gradiet Boost Recall Score: \", round(recall_score(Y_test, GB_label), 2))\n",
    "    \n",
    "# Computing Accuracy Score\n",
    "print(\"Gradiet Accuracy Score: \",round(accuracy_score(Y_test, GB_label), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f36425d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Recall Score:  0.7\n",
      "Random Forest Recall Score:  0.64\n"
     ]
    }
   ],
   "source": [
    "#### (ii) Creating Random Forest Model\n",
    "RF_md = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_train, Y_train)\n",
    "    \n",
    "# Predicting on test dataset\n",
    "RF_pred = RF_md.predict_proba(X_test)[:,1]\n",
    "RF_label = np.where(RF_pred > 0.15, 1, 0)\n",
    "    \n",
    "# Computing Recall Score\n",
    "print(\"Random Forest Recall Score: \",round(recall_score(Y_test, RF_label), 2))\n",
    "    \n",
    "# Computing Accuracy\n",
    "print(\"Random Forest Recall Score: \",round(accuracy_score(Y_test, RF_label), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a11582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Model Recall Score:  0.98\n",
      "AdaBoost Model Accuracy Score:  0.18\n"
     ]
    }
   ],
   "source": [
    "#### (iii) Creating AdaBoost Model\n",
    "AB_md = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "# Predicting on test dataset\n",
    "AB_pred = AB_md.predict_proba(X_test)[:,1]\n",
    "AB_label = np.where(AB_pred > 0.15, 1, 0)\n",
    "    \n",
    "# Computing Recall Score\n",
    "print(\"AdaBoost Model Recall Score: \", round(recall_score(Y_test, AB_label), 2))\n",
    "    \n",
    "# Computing Accuracy Score\n",
    "print(\"AdaBoost Model Accuracy Score: \", round(accuracy_score(Y_test, AB_label), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b20f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.494130</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.112399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483430</td>\n",
       "      <td>0.095037</td>\n",
       "      <td>0.096624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.101098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.489952</td>\n",
       "      <td>0.278278</td>\n",
       "      <td>0.247812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.478268</td>\n",
       "      <td>0.183730</td>\n",
       "      <td>0.183867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         0         0  TenYearCHD\n",
       "0  0.494130  0.123010  0.112399           0\n",
       "1  0.483430  0.095037  0.096624           0\n",
       "2  0.485900  0.096935  0.101098           0\n",
       "3  0.489952  0.278278  0.247812           0\n",
       "4  0.478268  0.183730  0.183867           0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensembeling of likelyhood\n",
    "X_rf = pd.concat([pd.DataFrame(AB_pred), pd.DataFrame(GB_pred), pd.DataFrame(RF_pred), Y_test.reset_index(drop = True)], axis = 1)\n",
    "X_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eeb83888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.412085</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.114027</td>\n",
       "      <td>0.082671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384788</td>\n",
       "      <td>0.095037</td>\n",
       "      <td>0.095797</td>\n",
       "      <td>0.087463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389945</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.100940</td>\n",
       "      <td>0.076177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453196</td>\n",
       "      <td>0.278278</td>\n",
       "      <td>0.247348</td>\n",
       "      <td>0.206495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430571</td>\n",
       "      <td>0.183730</td>\n",
       "      <td>0.186347</td>\n",
       "      <td>0.169115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         0         0         0  TenYearCHD\n",
       "0  0.412085  0.123010  0.114027  0.082671           0\n",
       "1  0.384788  0.095037  0.095797  0.087463           0\n",
       "2  0.389945  0.096935  0.100940  0.076177           0\n",
       "3  0.453196  0.278278  0.247348  0.206495           0\n",
       "4  0.430571  0.183730  0.186347  0.169115           0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining input and target\n",
    "X_rf_1 = pd.concat([pd.DataFrame(AB_pred), pd.DataFrame(GB_pred), pd.DataFrame(RF_pred)], axis = 1)\n",
    "\n",
    "# Building the Random Forest Model\n",
    "RF_md = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_rf_1, Y_test)\n",
    "\n",
    "#GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_rf_1, Y_train)\n",
    "\n",
    "# Extracting the ensemble likelyhood\n",
    "RF_preds = RF_md.predict_proba(X_rf_1)[:,1]\n",
    "\n",
    "# Final results\n",
    "final_results = pd.concat([pd.DataFrame(AB_pred), pd.DataFrame(GB_pred), pd.DataFrame(RF_pred), pd.DataFrame(RF_preds), Y_test.reset_index(drop = True)], axis = 1)\n",
    "final_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5de79aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Recal Score:  0.86\n",
      "Random Forest Accuracy Score:  0.71\n"
     ]
    }
   ],
   "source": [
    "# Labeling predictions\n",
    "RF_label = np.where(RF_preds > 0.15, 1, 0)\n",
    "\n",
    "# Computing Recall Score\n",
    "print(\"Random Forest Recal Score: \", round(recall_score(Y_test, RF_label), 2))\n",
    "    \n",
    "# Computing Accuracy\n",
    "print(\"Random Forest Accuracy Score: \", round(accuracy_score(Y_test, RF_label), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90950eee",
   "metadata": {},
   "source": [
    "#### By setting the hyper-parameter learning_rate to 0.01, increasing the cutoff value to 0.15 and aggregating all models predictions in a strong prediction, I could significantly increase the metrics values as displayed above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
