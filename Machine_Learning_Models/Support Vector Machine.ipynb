{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "#### What is a perceptron? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a single-layer neural network used in classification tasks while working with a set of input data. Since perceptron uses classified data points which are already labeled, it is a supervised learning algorithm. This algorithm is used to enable neurons to learn and process elements in the training set one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "#### What are the different types of perceptrons? Briefly describe each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of perceptrons:\\\n",
    "  - Single-layer perceptrons: single-layer perceptrons can learn only linearly separable patterns.\\\n",
    "  - Multi-layer perceptrons: multi-layer perceptrons, also known as feed-forward net-works, contain at least one hidden layer with a non-linear activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "#### What is a hard margin in a support vector machine model? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hard-margin in a support vector machine model refers to fitting a model with zero errors in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "#### The effectiveness of a support vector machine model depends on:\n",
    "(a) kernel\\\n",
    "(b) kernel parameters\\\n",
    "(c) penalty cost parameter\\\n",
    "(d) All of the above\n",
    "(e) None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "#### What is/are true about kernel in SVM?\n",
    "(a) Kernel function map low dimensional data into high dimensional space.\\\n",
    "(b) Kernel function map high dimensional data into low dimensional space.\\\n",
    "(c) It is a similarity function.\\\n",
    "(d) (a) and (c)\\\n",
    "(e) (b) and (c)\\\n",
    "(f) (a), (b) and (c)\\\n",
    "(g) None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) (a) and (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.6.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.14.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.41.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: keras~=2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "#### (a) Load the data file to you S3 bucket. Using the pandas library, read the csv data file and create a data-frame called heart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4238, 16)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'gabrielferreira-data-455-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Defining the file to be read from s3 bucket\n",
    "file_key = \"framingham.csv\"\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "# Reading the csv file\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "heart.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Remove observations with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3656, 16)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart = heart.dropna()\n",
    "heart = heart.reset_index(drop = True)\n",
    "heart.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Using age, currentSmoker, totChol, BMI, and heartRate as the predictor variables, and TenYearCHD as the target variable, do the following:\n",
    "(i) Split the data into train (80%) and test (20%).\\\n",
    "(ii) Using MinMaxScaler, transform all the input variables in the train and test datasets\n",
    "to 0-1 scale.\n",
    "\n",
    "• Build a multi-layer perceptron model with one single hidden layer with 4 neurons\n",
    "(hyperbolic tangent as the activation function) and softmax as the activation function for the output. Use the stochastic descent gradient as the method to estimate\n",
    "the weights (optimizer = ’sgd’) and metrics = [’accuracy’]. Use epochs =\n",
    "100 and batch size = 500 to build the model. After that, use the model to predict on the test dataset. Using 15% as the cut-off value, report the recall of this\n",
    "model.\n",
    "\n",
    "• Build a multi-layer perceptron model with one single hidden layer with 4 neurons (ReLU as the activation function) and softmax as the activation function for\n",
    "the output. Use the stochastic descent gradient as the method to estimate the\n",
    "weights (optimizer = ’sgd’) and metrics = [’accuracy’]. Use epochs = 100\n",
    "and batch size = 500 to build the model. After that, use the model to predict\n",
    "on the test dataset. Using 15% as the cut-off value, report the recall of this model.\n",
    "\n",
    "• Build a support vector machine model using rbf as the kernel. After that, use the\n",
    "model to predict on the test dataset. Using 15% as the cut-off value, report the\n",
    "recall of this model.\n",
    "\n",
    "• Build a support vector machine model using poly as the kernel. After that, use\n",
    "the model to predict on the test dataset. Using 15% as the cut-off value, report\n",
    "the recall of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining predictor and target variables\n",
    "X = heart[['age', 'currentSmoker', 'totChol', 'BMI', 'heartRate']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "# Transforming the input data to 0-1 scale\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72972973, 0.        , 0.37214137, 0.23145904, 0.39393939],\n",
       "       [0.16216216, 1.        , 0.31392931, 0.1565681 , 0.31313131],\n",
       "       [0.67567568, 0.        , 0.24948025, 0.47624818, 0.14141414],\n",
       "       ...,\n",
       "       [0.51351351, 0.        , 0.26195426, 0.22976248, 0.46464646],\n",
       "       [0.24324324, 1.        , 0.21621622, 0.2190984 , 0.28282828],\n",
       "       [0.10810811, 1.        , 0.10602911, 0.2535143 , 0.36363636]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11304347826086956"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md1 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'tanh'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "\n",
    "md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "md1.fit(X_train,\n",
    "        tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "        epochs = 100, \n",
    "        batch_size =500, \n",
    "        verbose = 0,\n",
    "        validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)))\n",
    "        \n",
    "from sklearn.metrics import recall_score\n",
    "preds = md1.predict(X_test)[:,1]\n",
    "preds = np.where(preds < 0.15, 0, 1)\n",
    "recall_score(Y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md2 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "md2.fit(X_train,\n",
    "        tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "        epochs = 100, \n",
    "        batch_size =500, \n",
    "        verbose = 0,\n",
    "        validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)))\n",
    "        \n",
    "\n",
    "preds_2 = md2.predict(X_test)[:,1]\n",
    "preds_2 = np.where(preds_2 < 0.15, 0, 1)\n",
    "recall_score(Y_test, preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6434782608695652"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the svm with kernel = 'rbf'\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "# Building the svm with kernel = 'rbf'\n",
    "md3 = SVC(kernel = 'rbf', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "# Predicting on the test dataset\n",
    "preds_3 = md3.predict_proba(X_test)[:,1]\n",
    "preds_3 = np.where(preds_3 < 0.15, 0, 1)\n",
    "recall_score(Y_test, preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5043478260869565"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the svm with kernel = 'poly'\n",
    "md4 = SVC(kernel = 'poly', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "# Predicting on the test dataset\n",
    "preds_4 = md4.predict_proba(X_test)[:,1]\n",
    "preds_4 = np.where(preds_4 < 0.15, 0, 1)\n",
    "recall_score(Y_test, preds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md1_recall = list()\n",
    "md2_recall = list()\n",
    "md3_recall = list()\n",
    "md4_recall = list()\n",
    "\n",
    "for i in range(0,100):\n",
    "    # Defining predictor and target variables\n",
    "    X = heart[['age', 'currentSmoker', 'totChol', 'BMI', 'heartRate']]\n",
    "    Y = heart['TenYearCHD']\n",
    "\n",
    "    # Splitting the data into train and test\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "    # Transforming the input data to 0-1 scale\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    \n",
    "    # Model 1\n",
    "    md1 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'tanh'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    md1.fit(X_train,\n",
    "        tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "        epochs = 100, \n",
    "        batch_size =500, \n",
    "        verbose = 0,\n",
    "        validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)))\n",
    "        \n",
    "    from sklearn.metrics import recall_score\n",
    "    preds = md1.predict(X_test)[:,1]\n",
    "    preds = np.where(preds < 0.15, 0, 1)\n",
    "    md1_recall.append(recall_score(Y_test, preds))\n",
    "\n",
    "\n",
    "     # Model 2\n",
    "    md2 = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(4, input_dim = 5, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    md2.fit(X_train,\n",
    "        tf.keras.utils.to_categorical(Y_train, num_classes = 2), \n",
    "        epochs = 100, \n",
    "        batch_size =500, \n",
    "        verbose = 0,\n",
    "        validation_data = (X_test, tf.keras.utils.to_categorical(Y_test, num_classes = 2)))\n",
    "        \n",
    "\n",
    "    preds_2 = md2.predict(X_test)[:,1]\n",
    "    preds_2 = np.where(preds_2 < 0.15, 0, 1)\n",
    "    md2_recall.append(recall_score(Y_test, preds_2))\n",
    "    \n",
    "    # Model 3\n",
    "    # Building the svm with kernel = 'rbf'\n",
    "    md3 = SVC(kernel = 'rbf', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "    # Predicting on the test dataset\n",
    "    preds_3 = md3.predict_proba(X_test)[:,1]\n",
    "    preds_3 = np.where(preds_3 < 0.15, 0, 1)\n",
    "    md3_recall.append(recall_score(Y_test, preds_3))\n",
    "    \n",
    "    # Model 4\n",
    "    # Building the svm with karmel = 'poly'\n",
    "    md4 = SVC(kernel = 'poly', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "    # Predicting on the test dataset\n",
    "    preds_4 = md4.predict_proba(X_test)[:,1]\n",
    "    preds_4 = np.where(preds_4 < 0.15, 0, 1)\n",
    "    md4_recall.append(recall_score(Y_test, preds_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing model 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Plotting iteration results\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "\n",
    "iterations = range(0, 100)\n",
    "plt.plot(iterations, md1_recall, marker = 'o', color = 'blue',\n",
    "        label = 'First Model')\n",
    "plt.plot(iterations, md2_recall, marker = 'o', color = 'orange',\n",
    "        label = 'Second Model')\n",
    "plt.plot(iterations, md3_recall, marker = 'o', color = 'red',\n",
    "         label = 'Third Model')\n",
    "plt.plot(iterations, md4_recall, marker = 'o', color = 'black',\n",
    "        label = 'Fourth Model')\n",
    "plt.xlabel('Number of Iteration')\n",
    "plt.ylabel('Recall Score')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md1_avg_recall = np.mean(md1_recall)\n",
    "md2_avg_recall = np.mean(md2_recall)\n",
    "md3_avg_recall = np.mean(md3_recall)\n",
    "md4_avg_recall = np.mean(md4_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average recall score of the model 1: ', round(md1_avg_recall, 2))\n",
    "print('Average recall score of the model 2: ', round(md2_avg_recall, 2))\n",
    "print('Average recall score of the model 3: ', round(md3_avg_recall, 2))\n",
    "print('Average recall score of the model 4: ', round(md4_avg_recall, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model I would use to predict TenYearCHD is the model 3 because its recall score, in average, is the highest among the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
