{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f9aea2",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "#### (c) LOOCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc466f9",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "#### (c) high bias and low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafad383",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "#### (b) low bias and high variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74ce55",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "#### Explain what regularization is and why it is useful.\n",
    "\n",
    "Regularization, also known as shrinkage, is a technique that involves fitting a model involving all the input variables. This technique is known for tuning the function by adding an additional penalty term in the error function. This penalty is useful because the estimated coefficients are shrinken towards zero, which causes an effect of reducing the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537aecd5",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e004621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (a)\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'gabrielferreira-data-455-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Defining the file to be read from s3 bucket\n",
    "file_key = \"framingham.csv\"\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "# Reading the csv file\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "heart.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "813e33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping NAs\n",
    "heart = heart.dropna()\n",
    "heart = heart.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78859739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0a0dfdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input and target variables\n",
    "X = heart[['age', 'currentSmoker', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "#fitting data\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X), columns = X.columns)\n",
    "\n",
    "# Defining list to store results\n",
    "md1_f1 = []\n",
    "md2_f1 = []\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for train_ix, test_ix in kfold.split(X):\n",
    "    \n",
    "    ## Splitting data into train and validation\n",
    "    X_train, X_val = X.loc[train_ix], X.loc[test_ix]\n",
    "   \n",
    "    # Defining input and target variables for the new model\n",
    "    X_train_new = X_train.drop(columns = ['sysBP', 'diaBP'], axis = 1)\n",
    "    X_val_new = X_val.drop(columns = ['sysBP', 'diaBP'], axis = 1)\n",
    "    \n",
    "    Y_train, Y_val = Y.loc[train_ix], Y.loc[test_ix]\n",
    "    \n",
    "   \n",
    "    # Building a logistic regression model\n",
    "    logit_md1 = LogisticRegression().fit(X_train, Y_train)\n",
    "    logit_md2 = LogisticRegression().fit(X_train_new, Y_train)\n",
    "\n",
    "    # Getting predictions from logit_md1 on X_test dataset\n",
    "    md1_preds = logit_md1.predict_proba(X_val)[:,1]\n",
    "    md2_preds = logit_md2.predict_proba(X_val_new)[:,1]\n",
    "    \n",
    "    # Defining likelyhoods to labels\n",
    "    md1_preds = np.where(md1_preds < 0.25, 0, 1)\n",
    "    md2_preds = np.where(md2_preds < 0.25, 0, 1)\n",
    "    \n",
    "    # Computing the F1-Score for model 1\n",
    "    md1_f1.append(f1_score(Y_val, md1_preds))\n",
    "    md2_f1.append(f1_score(Y_val, md2_preds))\n",
    " \n",
    "    # Calculating the average of the F1-Scores\n",
    "    md1_avg_f1 = np.mean(md1_f1)\n",
    "    md2_avg_f1 = np.mean(md2_f1)\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    # Building a logistic regression model\n",
    "    logit_md2 = LogisticRegression().fit(X_train_new, Y_train)\n",
    "    \n",
    "    # Getting predictions from logit_md1 on X_test dataset\n",
    "    md2_preds = logit_md2.predict_proba(X_val_new)[:,1]\n",
    "    \n",
    "    # Defining likelyhoods to labels\n",
    "    md2_preds = np.where(md2_preds < 0.25, 0, 1)\n",
    "    \n",
    "    # Computing the F1-Score for model 2\n",
    "    md2_f1.append(f1_score(Y_val, md2_preds))\n",
    "    \n",
    "    # Calculating the average of the F1-Scores\n",
    "    md2_avg_f1 = np.mean(md2_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3e620ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average F1-score of the model 1 is  34.09 %\n",
      "The average F1-score of the model 2 is  31.41 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The average F1-score of the model 1 is \", round(md1_avg_f1*100, 2), \"%\")\n",
    "print(\"The average F1-score of the model 2 is \", round(md2_avg_f1*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8ead4",
   "metadata": {},
   "source": [
    "#### I would use the first model to predict TenYearCHD because its F1-score is higher."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
