{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdabc97b",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3bb52a",
   "metadata": {},
   "source": [
    "(b) In gradient boosting trees, the decision trees are dependent of each other.\\\n",
    "(c) It is a method for improving the performance by aggregating the results of several decision\n",
    "trees.\n",
    "\n",
    "#### (f) (b) and (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6caaef",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f60281",
   "metadata": {},
   "source": [
    "I would choose the Scenario 2 with Depth equal to 4. I think this is a good number for this hyper-parameter amd it has a good Training and Validation Error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94193c22",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c404102",
   "metadata": {},
   "source": [
    "The main difference between ada boost and gradient boost is that gradient boost is more sensitive to outliers than ada boost. The reason for this is the difference in their loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef653622",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c6d1b",
   "metadata": {},
   "source": [
    "Gradient boosting provides predictive accuracy that it hard to be beat and it is an algorithm very flexible that can optimize on different loss functions, and provides several hyperparameter tuning options that make the function fit very flexible. Random Forest runs multiple models simultaneously and average the results in a strong prection to reduce variance. Gradiednt boosting is often more used becasue its metrics and flexibily are hard to be beat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8b6be",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d52843",
   "metadata": {},
   "source": [
    "#### (a) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5a3684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question 6\n",
    "#(a)\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "# Defining s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'gabrielferreira-data-455-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Defining the file to be read from s3 bucket\n",
    "key_file = 'framingham.csv'\n",
    "\n",
    "bucket_object = bucket.Object(key_file)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "# Reading csv\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "\n",
    "# Removing missing values\n",
    "heart = heart.dropna()\n",
    "heart.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba31986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction:  0\n",
      "Interaction:  1\n",
      "Interaction:  2\n",
      "Interaction:  3\n",
      "Interaction:  4\n",
      "Interaction:  5\n",
      "Interaction:  6\n",
      "Interaction:  7\n",
      "Interaction:  8\n",
      "Interaction:  9\n",
      "Interaction:  10\n",
      "Interaction:  11\n",
      "Interaction:  12\n",
      "Interaction:  13\n",
      "Interaction:  14\n",
      "Interaction:  15\n",
      "Interaction:  16\n",
      "Interaction:  17\n",
      "Interaction:  18\n",
      "Interaction:  19\n",
      "Interaction:  20\n",
      "Interaction:  21\n",
      "Interaction:  22\n",
      "Interaction:  23\n",
      "Interaction:  24\n",
      "Interaction:  25\n",
      "Interaction:  26\n",
      "Interaction:  27\n",
      "Interaction:  28\n",
      "Interaction:  29\n",
      "Interaction:  30\n",
      "Interaction:  31\n",
      "Interaction:  32\n",
      "Interaction:  33\n",
      "Interaction:  34\n",
      "Interaction:  35\n",
      "Interaction:  36\n",
      "Interaction:  37\n",
      "Interaction:  38\n",
      "Interaction:  39\n",
      "Interaction:  40\n",
      "Interaction:  41\n",
      "Interaction:  42\n",
      "Interaction:  43\n",
      "Interaction:  44\n",
      "Interaction:  45\n",
      "Interaction:  46\n",
      "Interaction:  47\n",
      "Interaction:  48\n",
      "Interaction:  49\n",
      "Interaction:  50\n",
      "Interaction:  51\n",
      "Interaction:  52\n",
      "Interaction:  53\n",
      "Interaction:  54\n",
      "Interaction:  55\n",
      "Interaction:  56\n",
      "Interaction:  57\n",
      "Interaction:  58\n",
      "Interaction:  59\n",
      "Interaction:  60\n",
      "Interaction:  61\n",
      "Interaction:  62\n",
      "Interaction:  63\n",
      "Interaction:  64\n",
      "Interaction:  65\n",
      "Interaction:  66\n",
      "Interaction:  67\n",
      "Interaction:  68\n",
      "Interaction:  69\n",
      "Interaction:  70\n",
      "Interaction:  71\n",
      "Interaction:  72\n",
      "Interaction:  73\n",
      "Interaction:  74\n",
      "Interaction:  75\n",
      "Interaction:  76\n",
      "Interaction:  77\n",
      "Interaction:  78\n",
      "Interaction:  79\n",
      "Interaction:  80\n",
      "Interaction:  81\n",
      "Interaction:  82\n",
      "Interaction:  83\n",
      "Interaction:  84\n",
      "Interaction:  85\n",
      "Interaction:  86\n",
      "Interaction:  87\n",
      "Interaction:  88\n",
      "Interaction:  89\n",
      "Interaction:  90\n",
      "Interaction:  91\n",
      "Interaction:  92\n",
      "Interaction:  93\n",
      "Interaction:  94\n",
      "Interaction:  95\n",
      "Interaction:  96\n",
      "Interaction:  97\n",
      "Interaction:  98\n",
      "Interaction:  99\n"
     ]
    }
   ],
   "source": [
    "# Defining target and predictor variables\n",
    "X = heart[['age', 'totChol', 'sysBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "    \n",
    "# Creating lists to store the recall score for each model\n",
    "RFM_recall = list()\n",
    "ABM_recall = list()\n",
    "GBM_recall = list()\n",
    "\n",
    "# Creating lists to store the accuracy score for each model\n",
    "RFM_accuracy = list()\n",
    "ABM_accuracy = list()\n",
    "GBM_accuracy = list()\n",
    "\n",
    "# Creating for loop to get 100 recall and accuracy scores of each model\n",
    "for i in range(0,100):\n",
    "    \n",
    "    # (i) Splitting the dataset into train and test\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    #### (ii) Creating Random Forest Model\n",
    "    RF_md = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    RF_pred = RF_md.predict_proba(X_test)[:,1]\n",
    "    RF_pred = np.where(RF_pred > 0.1, 1, 0)\n",
    "    \n",
    "    # Computing Recall Score\n",
    "    RFM_recall.append(round(recall_score(Y_test, RF_pred), 2))\n",
    "    \n",
    "    # Computing Accuracy\n",
    "    RFM_accuracy.append(round(accuracy_score(Y_test, RF_pred), 2))\n",
    "    \n",
    "    #### (iii) Creating AdaBoost Model\n",
    "    AB_md = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators = 500).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    AB_pred = AB_md.predict_proba(X_test)[:,1]\n",
    "    AB_pred = np.where(AB_pred > 0.1, 1, 0)\n",
    "    \n",
    "    # Computing Recall Score\n",
    "    ABM_recall.append(round(recall_score(Y_test, AB_pred), 2))\n",
    "    \n",
    "    # Computing Accuracy Score\n",
    "    ABM_accuracy.append(round(accuracy_score(Y_test, AB_pred), 2))\n",
    "    \n",
    "    #### (iv) Creating Gradiet Boost Model\n",
    "    GB_md = GradientBoostingClassifier(max_depth = 3, n_estimators = 500).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    GB_pred = GB_md.predict_proba(X_test)[:,1]\n",
    "    GB_pred = np.where(GB_pred > 0.1, 1, 0)\n",
    "    \n",
    "    # Computing Recall Score\n",
    "    GBM_recall.append(round(recall_score(Y_test, GB_pred), 2))\n",
    "    \n",
    "    # Computing Accuracy Score\n",
    "    GBM_accuracy.append(round(accuracy_score(Y_test, GB_pred), 2))\n",
    "    print(\"Interaction: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3cd6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.8552</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metrics  RandomForest  AdaBoost  GradientBoosting\n",
       "0    Recall        0.8552      1.00            0.6335\n",
       "1  Accuracy        0.4525      0.15            0.5891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = pd.DataFrame({\"Metrics\": [\"Recall\", \"Accuracy\"],\n",
    "                               \"RandomForest\": [np.mean(RFM_recall), np.mean(RFM_accuracy)],\n",
    "                               \"AdaBoost\": [np.mean(ABM_recall), np.mean(ABM_accuracy)],\n",
    "                               \"GradientBoosting\": [np.mean(GBM_recall), np.mean(GBM_accuracy)]})\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4670e",
   "metadata": {},
   "source": [
    "I would say the model that had the best performance was Gradieting Boost. Although it did not reach the minimum metrics, which are equal to 80%, it had the best balance between Recall and Accuracy among all models. I would recommend, in this case, to change or add hyper-parameters such as learning rate, increasing the cutoff value, or combining these above likelyhoods in a stroger prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f2ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining target and predictor variables\n",
    "X = heart[['age', 'totChol', 'sysBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "# (i) Splitting the dataset into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ce0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradiet Boost Recall Score:  0.69\n",
      "Gradiet Accuracy Score:  0.66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### (iv) Creating Gradiet Boost Model\n",
    "GB_md = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "# Predicting on test dataset\n",
    "GB_pred = GB_md.predict_proba(X_test)[:,1]\n",
    "GB_label = np.where(GB_pred > 0.15, 1, 0)\n",
    "    \n",
    "# Computing Recall Score\n",
    "print(\"Gradiet Boost Recall Score: \", round(recall_score(Y_test, GB_label), 2))\n",
    "    \n",
    "# Computing Accuracy Score\n",
    "print(\"Gradiet Accuracy Score: \",round(accuracy_score(Y_test, GB_label), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d43c1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Recall Score:  0.7\n",
      "Random Forest Recall Score:  0.64\n"
     ]
    }
   ],
   "source": [
    "#### (ii) Creating Random Forest Model\n",
    "RF_md = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_train, Y_train)\n",
    "    \n",
    "# Predicting on test dataset\n",
    "RF_pred = RF_md.predict_proba(X_test)[:,1]\n",
    "RF_label = np.where(RF_pred > 0.15, 1, 0)\n",
    "    \n",
    "# Computing Recall Score\n",
    "print(\"Random Forest Recall Score: \",round(recall_score(Y_test, RF_label), 2))\n",
    "    \n",
    "# Computing Accuracy\n",
    "print(\"Random Forest Recall Score: \",round(accuracy_score(Y_test, RF_label), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21a2a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Model Recall Score:  0.98\n",
      "AdaBoost Model Accuracy Score:  0.18\n"
     ]
    }
   ],
   "source": [
    "#### (iii) Creating AdaBoost Model\n",
    "AB_md = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "# Predicting on test dataset\n",
    "AB_pred = AB_md.predict_proba(X_test)[:,1]\n",
    "AB_label = np.where(AB_pred > 0.15, 1, 0)\n",
    "    \n",
    "# Computing Recall Score\n",
    "print(\"AdaBoost Model Recall Score: \", round(recall_score(Y_test, AB_label), 2))\n",
    "    \n",
    "# Computing Accuracy Score\n",
    "print(\"AdaBoost Model Accuracy Score: \", round(accuracy_score(Y_test, AB_label), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8886d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.494130</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.112399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483430</td>\n",
       "      <td>0.095037</td>\n",
       "      <td>0.096624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.101098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.489952</td>\n",
       "      <td>0.278278</td>\n",
       "      <td>0.247812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.478268</td>\n",
       "      <td>0.183730</td>\n",
       "      <td>0.183867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         0         0  TenYearCHD\n",
       "0  0.494130  0.123010  0.112399           0\n",
       "1  0.483430  0.095037  0.096624           0\n",
       "2  0.485900  0.096935  0.101098           0\n",
       "3  0.489952  0.278278  0.247812           0\n",
       "4  0.478268  0.183730  0.183867           0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensembeling of likelyhood\n",
    "X_rf = pd.concat([pd.DataFrame(AB_pred), pd.DataFrame(GB_pred), pd.DataFrame(RF_pred), Y_test.reset_index(drop = True)], axis = 1)\n",
    "X_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b554e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.412085</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.114027</td>\n",
       "      <td>0.082671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384788</td>\n",
       "      <td>0.095037</td>\n",
       "      <td>0.095797</td>\n",
       "      <td>0.087463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389945</td>\n",
       "      <td>0.096935</td>\n",
       "      <td>0.100940</td>\n",
       "      <td>0.076177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453196</td>\n",
       "      <td>0.278278</td>\n",
       "      <td>0.247348</td>\n",
       "      <td>0.206495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430571</td>\n",
       "      <td>0.183730</td>\n",
       "      <td>0.186347</td>\n",
       "      <td>0.169115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         0         0         0  TenYearCHD\n",
       "0  0.412085  0.123010  0.114027  0.082671           0\n",
       "1  0.384788  0.095037  0.095797  0.087463           0\n",
       "2  0.389945  0.096935  0.100940  0.076177           0\n",
       "3  0.453196  0.278278  0.247348  0.206495           0\n",
       "4  0.430571  0.183730  0.186347  0.169115           0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining input and target\n",
    "X_rf_1 = pd.concat([pd.DataFrame(AB_pred), pd.DataFrame(GB_pred), pd.DataFrame(RF_pred)], axis = 1)\n",
    "\n",
    "# Building the Random Forest Model\n",
    "RF_md = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_rf_1, Y_test)\n",
    "\n",
    "#GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_rf_1, Y_train)\n",
    "\n",
    "# Extracting the ensemble likelyhood\n",
    "RF_preds = RF_md.predict_proba(X_rf_1)[:,1]\n",
    "\n",
    "# Final results\n",
    "final_results = pd.concat([pd.DataFrame(AB_pred), pd.DataFrame(GB_pred), pd.DataFrame(RF_pred), pd.DataFrame(RF_preds), Y_test.reset_index(drop = True)], axis = 1)\n",
    "final_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1569ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Recal Score:  0.86\n",
      "Random Forest Accuracy Score:  0.71\n"
     ]
    }
   ],
   "source": [
    "# Labeling predictions\n",
    "RF_label = np.where(RF_preds > 0.15, 1, 0)\n",
    "\n",
    "# Computing Recall Score\n",
    "print(\"Random Forest Recal Score: \", round(recall_score(Y_test, RF_label), 2))\n",
    "    \n",
    "# Computing Accuracy\n",
    "print(\"Random Forest Accuracy Score: \", round(accuracy_score(Y_test, RF_label), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aea461",
   "metadata": {},
   "source": [
    "#### By setting the hyper-parameter learning_rate to 0.01, increasing the cutoff value to 0.15 and aggregating all models predictions in a strong prediction, I could significantly increase the metrics values as displayed above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
