{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d170db",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "####  If a decision tree is under-fitting the training dataset, is it a good idea to try scaling the input features?\n",
    "It is not a good idea because decision tree is not sensible and does not depend on scaled input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f774047",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### If a decision tree is over-fitting the training dataset, is it a good idea to try decreasing max depth?\n",
    "It is a good idea because the deeper the tree is, more complex the model becomes. Therefore, if a decision tree is over-fitting the training dataset, you want to decrease the max_depth, it would increase the tranning error, but it also allows the model to indentify important patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b328842",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### Why would you use a random forest instead of a decision tree?\n",
    "#### (a) For a lower training error.\n",
    "#### (b) To reduce the variance of the model.\n",
    "#### (c) For a model that it is easier for human to interpret.\n",
    "\n",
    "---> (b) To reduce the variance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43aa8a",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Which of the following is/are TRUE about bagging trees?\n",
    "#### (a) In bagging trees, the trees are grown independent of each other.\n",
    "#### (b) In bagging trees, the trees are grown in sequence. 1\n",
    "#### (c) Bagging is a method for improving the performance by aggregating the results of weak learners.\n",
    "#### (d) (a) and (c)\n",
    "#### (e) (b) and (c)\n",
    "#### (f) None of the above.\n",
    "\n",
    "---> (d) (a) and (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a90282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question 6\n",
    "#\n",
    "3(a)\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Defining s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'gabrielferreira-data-455-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Defining the file to be read from s3 bucket\n",
    "key_file = 'framingham.csv'\n",
    "\n",
    "bucket_object = bucket.Object(key_file)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "# Reading csv\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "\n",
    "# (b)\n",
    "heart = heart.dropna()\n",
    "heart.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf291529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sysBP              0.135187\n",
       "BMI                0.127211\n",
       "age                0.124732\n",
       "totChol            0.121976\n",
       "glucose            0.119477\n",
       "diaBP              0.119008\n",
       "heartRate          0.096263\n",
       "cigsPerDay         0.050504\n",
       "education          0.036787\n",
       "male               0.021138\n",
       "prevalentHyp       0.018285\n",
       "currentSmoker      0.012654\n",
       "BPMeds             0.006994\n",
       "diabetes           0.006561\n",
       "prevalentStroke    0.003223\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (c)\n",
    "# Defining input and target variables\n",
    "X = heart.drop(columns = 'TenYearCHD')\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "# Computing feature importance\n",
    "feature_importance = list()\n",
    "\n",
    "# Creating a foor loop to store 100 feature importances\n",
    "for i in range(0,100):\n",
    "    # Splitting the data into train and test\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    # Random Forest model variable selector\n",
    "    rf_md = RandomForestClassifier(n_estimators = 500).fit(X_train, Y_train)\n",
    "    \n",
    "    # Computing variable importance for each variable\n",
    "    feature_importance.append(rf_md.feature_importances_)\n",
    "\n",
    "# Seeing results\n",
    "feature_importance = pd.DataFrame(feature_importance, columns = X.columns)\n",
    "feature_importance = np.mean(feature_importance, axis = 0).sort_values(ascending = False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c298ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall_3</th>\n",
       "      <th>Recall_5</th>\n",
       "      <th>Recall_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844554</td>\n",
       "      <td>0.830536</td>\n",
       "      <td>0.817143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recall_3  Recall_5  Recall_7\n",
       "0  0.844554  0.830536  0.817143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (d)\n",
    "# Defining input variables according to Random Forest feature importance\n",
    "X = heart[['sysBP', 'BMI', 'age', 'totChol', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "# Computing recall score for each model\n",
    "recall_3 = list()\n",
    "recall_5 = list()\n",
    "recall_7 = list()\n",
    "\n",
    "# Creating a foor loop to store 100 recall score provided by the different max_depth\n",
    "for i in range(0, 100):\n",
    "    # Splitting the data into train and test using new predictors \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    ### Random Forest Classifier model with max_depth = 3\n",
    "    rf_md1 = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    pred1 = rf_md1.predict_proba(X_test)[:, 1]\n",
    "    pred1 = np.where(pred1 >= 0.1, 1, 0)\n",
    "    \n",
    "    # Computing recall\n",
    "    recall_3.append(recall_score(Y_test, pred1))\n",
    "    \n",
    "    ### Random Forest Classifier model with max_depth = 5\n",
    "    rf_md2 = RandomForestClassifier(n_estimators = 500, max_depth = 5).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    pred2 = rf_md2.predict_proba(X_test)[:, 1]\n",
    "    pred2 = np.where(pred2 >= 0.1, 1, 0)\n",
    "    \n",
    "    # Computing recall\n",
    "    recall_5.append(recall_score(Y_test, pred2))\n",
    "    \n",
    "    ### Random Forest Classifier model with max_depth = 7\n",
    "    rf_md3 = RandomForestClassifier(n_estimators = 500, max_depth = 7).fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting on test dataset\n",
    "    pred3 = rf_md3.predict_proba(X_test)[:, 1]\n",
    "    pred3 = np.where(pred3 >= 0.1, 1, 0)\n",
    "    \n",
    "    # Computing recall\n",
    "    recall_7.append(recall_score(Y_test, pred3))\n",
    "    \n",
    "# Seeing the average of the 100 interactions\n",
    "recall_avg = {\"Recall_3\": [np.mean(recall_3, axis = 0)], \"Recall_5\": [np.mean(recall_5, axis = 0)], \"Recall_7\": [np.mean(recall_7, axis = 0)]}\n",
    "recall_avg = pd.DataFrame(recall_avg)\n",
    "recall_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33441dda",
   "metadata": {},
   "source": [
    "#### I would use the Random Forest Classifier using 500 trees and maximum depth tree equal to 3 because it is the simplest model and has the highest recall score between the three models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
